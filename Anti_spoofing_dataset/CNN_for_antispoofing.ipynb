{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_for_antispoofing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfl8ePbUT2j3",
        "outputId": "e2d173ad-c611-4af9-a184-a9cf68e6971f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/gdrive/MyDrive/final_antispoofing.zip\" \"/content\""
      ],
      "metadata": {
        "id": "GmJUtPcmUjdl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "archive = zipfile.ZipFile('/content/final_antispoofing.zip')\n",
        "archive.extractall('/content')"
      ],
      "metadata": {
        "id": "BtestcEqYKva"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/final_antispoofing'\n",
        "train_dataset_dir = '/content/final_antispoofing/train'\n",
        "test_dataset_dir = '/content/final_antispoofing/test'"
      ],
      "metadata": {
        "id": "JXwHG1NpYp1B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.mkdir('/content/antispoofing_dataset')\n",
        "os.mkdir('/content/antispoofing_dataset/train')\n",
        "os.mkdir('/content/antispoofing_dataset/test')\n",
        "os.mkdir('/content/antispoofing_dataset/train/real')\n",
        "os.mkdir('/content/antispoofing_dataset/train/spoof')\n",
        "os.mkdir('/content/antispoofing_dataset/test/real')\n",
        "os.mkdir('/content/antispoofing_dataset/test/spoof')"
      ],
      "metadata": {
        "id": "vl8umeQsYtKZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/antispoofing_dataset/train'\n",
        "test_dir = '/content/antispoofing_dataset/test'"
      ],
      "metadata": {
        "id": "ktQPKYgmYuRQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "copying the dataset from older folder to newer folder"
      ],
      "metadata": {
        "id": "R7sFq9VPawPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "metadata": {
        "id": "PAinedtIYuN5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_splits(data_directory):\n",
        "  for split_type in os.listdir(data_directory):\n",
        "    path_to_split_type = os.path.join(data_directory,split_type)\n",
        "    for category in os.listdir(path_to_split_type):\n",
        "      path_to_category = os.path.join(path_to_split_type,category)\n",
        "      for subject in os.listdir(path_to_category):\n",
        "        path_to_subject = os.path.join(path_to_category,subject)\n",
        "        for img in os.listdir(path_to_subject):\n",
        "          if split_type == 'train':\n",
        "            shutil.copy(os.path.join(path_to_subject,img),os.path.join(train_dir,category,img))\n",
        "          else:\n",
        "            shutil.copy(os.path.join(path_to_subject,img),os.path.join(test_dir,category,img))\n",
        "            \n",
        "  "
      ],
      "metadata": {
        "id": "SwBUPHZQbHFX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_splits(data_directory=dataset_dir)"
      ],
      "metadata": {
        "id": "txpaeahvYuKZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['real','spoof']"
      ],
      "metadata": {
        "id": "Yt7i4DcFYuGB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-----------------------Exploring Training Datasets-------------------\")\n",
        "for category in categories:\n",
        "  path=os.path.join(train_dir,category)\n",
        "  if category == 'real':\n",
        "    r1 = len(os.listdir(path))\n",
        "  else:\n",
        "    s1 = len(os.listdir(path))\n",
        "  print('There are {} images in {} directory'.format(len(os.listdir(path)),category))\n",
        "print('There are {} total images in training directory'.format(r1+s1))\n",
        "print(\"-----------------------Exploring Testing Datasets-------------------\")\n",
        "for category in categories:\n",
        "  path=os.path.join(test_dir,category)\n",
        "  if category == 'real':\n",
        "    r2 = len(os.listdir(path))\n",
        "  else:\n",
        "    s2 = len(os.listdir(path))\n",
        "  print('There are {} images in {} directory'.format(len(os.listdir(path)),category))\n",
        "print('There are {} total images in testing directory'.format(r2+s2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJMaBfHDYuBP",
        "outputId": "a7572c56-cf4b-40fa-8c91-061decd1713b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------Exploring Training Datasets-------------------\n",
            "There are 2102 images in real directory\n",
            "There are 2118 images in spoof directory\n",
            "There are 4220 total images in training directory\n",
            "-----------------------Exploring Testing Datasets-------------------\n",
            "There are 477 images in real directory\n",
            "There are 474 images in spoof directory\n",
            "There are 951 total images in testing directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "z9ua83s8Yt6J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(brightness_range = (0.8,1.2),\n",
        "                                   rotation_range = 30,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   fill_mode='nearest',\n",
        "                                   rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory(train_dir,target_size = (160,160),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 class_mode='binary',batch_size=25,\n",
        "                                                 shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x5A-YKHmXwT",
        "outputId": "b3fdfe7c-be3f-4958-e795-52e39bc30191"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4220 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(test_dir,target_size = (160,160),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 class_mode='binary',batch_size=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DvkeQIumX4G",
        "outputId": "15e43a21-8071-46b1-aff0-9e8c01b5d7da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 951 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building CNN"
      ],
      "metadata": {
        "id": "YzHqLzxbpQt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the CNN\n",
        "cnn = tf.keras.models.Sequential()\n",
        "# Convolution\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[160,160,3]))\n",
        "# MaxPooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "# Adding a second Convolution Layer\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
        "# flattening\n",
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "actehk7ZmX7_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Connection\n",
        "cnn.add(tf.keras.layers.Dense(units=120,kernel_initializer='he_normal',activation='relu'))\n",
        "# Hidden layer\n",
        "cnn.add(tf.keras.layers.Dense(units=120,kernel_initializer='he_normal',activation='relu'))\n",
        "# Hidden layer\n",
        "cnn.add(tf.keras.layers.Dense(units=120,kernel_initializer='he_normal',activation='relu'))\n",
        "# Hidden layer\n",
        "cnn.add(tf.keras.layers.Dense(units=120,kernel_initializer='he_normal',activation='relu'))\n",
        "# Output layer\n",
        "cnn.add(tf.keras.layers.Dense(units=1,kernel_initializer='glorot_normal',activation='sigmoid'))"
      ],
      "metadata": {
        "id": "1cOcn4XjmX_o"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xl-CJXwTmYFv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1opvkHSmYIn",
        "outputId": "4ffcf6cf-9e1e-4a73-d92b-17b1f5867d87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 158, 158, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 79, 79, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 77, 77, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 38, 38, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 46208)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               5545080   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 120)               14520     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 120)               14520     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               14520     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 121       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,598,905\n",
            "Trainable params: 5,598,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.mkdir('/content/model_weights')"
      ],
      "metadata": {
        "id": "tc1o-_sWuYUl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import model_from_json\n",
        "import json\n",
        "model_checkpoint = ModelCheckpoint('./model_weights/finalyearproject_antispoofing_model_{epoch:02d}-{val_accuracy:.6f}.h5',monitor='val_loss',mode='min',verbose=1,save_best_only=True,save_weights_only=True)"
      ],
      "metadata": {
        "id": "j5ADczGguYSP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import callbacks\n",
        "history = cnn.fit(x = training_set, validation_data = test_set, epochs = 100,callbacks=[model_checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Majp9V0jmYL3",
        "outputId": "3aeba6d6-8e5e-4243-f02c-07c839fb1a48"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.7692\n",
            "Epoch 00001: val_loss improved from inf to 0.57745, saving model to ./model_weights/finalyearproject_antispoofing_model_01-0.797056.h5\n",
            "169/169 [==============================] - 49s 212ms/step - loss: 0.4668 - accuracy: 0.7692 - val_loss: 0.5774 - val_accuracy: 0.7971\n",
            "Epoch 2/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.8924\n",
            "Epoch 00002: val_loss improved from 0.57745 to 0.29508, saving model to ./model_weights/finalyearproject_antispoofing_model_02-0.845426.h5\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.2607 - accuracy: 0.8924 - val_loss: 0.2951 - val_accuracy: 0.8454\n",
            "Epoch 3/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.2488 - accuracy: 0.8988\n",
            "Epoch 00003: val_loss improved from 0.29508 to 0.21772, saving model to ./model_weights/finalyearproject_antispoofing_model_03-0.899054.h5\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.2488 - accuracy: 0.8988 - val_loss: 0.2177 - val_accuracy: 0.8991\n",
            "Epoch 4/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9199\n",
            "Epoch 00004: val_loss did not improve from 0.21772\n",
            "169/169 [==============================] - 35s 210ms/step - loss: 0.1956 - accuracy: 0.9199 - val_loss: 0.2790 - val_accuracy: 0.8717\n",
            "Epoch 5/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9358\n",
            "Epoch 00005: val_loss did not improve from 0.21772\n",
            "169/169 [==============================] - 35s 210ms/step - loss: 0.1712 - accuracy: 0.9358 - val_loss: 0.3969 - val_accuracy: 0.8454\n",
            "Epoch 6/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9296\n",
            "Epoch 00006: val_loss improved from 0.21772 to 0.14390, saving model to ./model_weights/finalyearproject_antispoofing_model_06-0.935857.h5\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.1719 - accuracy: 0.9296 - val_loss: 0.1439 - val_accuracy: 0.9359\n",
            "Epoch 7/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9481\n",
            "Epoch 00007: val_loss improved from 0.14390 to 0.14003, saving model to ./model_weights/finalyearproject_antispoofing_model_07-0.939012.h5\n",
            "169/169 [==============================] - 35s 210ms/step - loss: 0.1465 - accuracy: 0.9481 - val_loss: 0.1400 - val_accuracy: 0.9390\n",
            "Epoch 8/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9502\n",
            "Epoch 00008: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.1283 - accuracy: 0.9502 - val_loss: 0.3831 - val_accuracy: 0.8538\n",
            "Epoch 9/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9448\n",
            "Epoch 00009: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 35s 208ms/step - loss: 0.1315 - accuracy: 0.9448 - val_loss: 0.2312 - val_accuracy: 0.9001\n",
            "Epoch 10/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9576\n",
            "Epoch 00010: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 35s 207ms/step - loss: 0.1118 - accuracy: 0.9576 - val_loss: 0.1761 - val_accuracy: 0.9253\n",
            "Epoch 11/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9659\n",
            "Epoch 00011: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0944 - accuracy: 0.9659 - val_loss: 0.1829 - val_accuracy: 0.9169\n",
            "Epoch 12/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9540\n",
            "Epoch 00012: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 35s 208ms/step - loss: 0.1197 - accuracy: 0.9540 - val_loss: 0.3145 - val_accuracy: 0.8707\n",
            "Epoch 13/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9616\n",
            "Epoch 00013: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.1097 - accuracy: 0.9616 - val_loss: 0.6379 - val_accuracy: 0.8244\n",
            "Epoch 14/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9713\n",
            "Epoch 00014: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 36s 216ms/step - loss: 0.0815 - accuracy: 0.9713 - val_loss: 0.2261 - val_accuracy: 0.8980\n",
            "Epoch 15/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9699\n",
            "Epoch 00015: val_loss did not improve from 0.14003\n",
            "169/169 [==============================] - 37s 219ms/step - loss: 0.0837 - accuracy: 0.9699 - val_loss: 0.2060 - val_accuracy: 0.8980\n",
            "Epoch 16/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9680\n",
            "Epoch 00016: val_loss improved from 0.14003 to 0.08653, saving model to ./model_weights/finalyearproject_antispoofing_model_16-0.966351.h5\n",
            "169/169 [==============================] - 38s 222ms/step - loss: 0.0894 - accuracy: 0.9680 - val_loss: 0.0865 - val_accuracy: 0.9664\n",
            "Epoch 17/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9718\n",
            "Epoch 00017: val_loss did not improve from 0.08653\n",
            "169/169 [==============================] - 37s 221ms/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 0.2885 - val_accuracy: 0.8791\n",
            "Epoch 18/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9742\n",
            "Epoch 00018: val_loss did not improve from 0.08653\n",
            "169/169 [==============================] - 37s 220ms/step - loss: 0.0688 - accuracy: 0.9742 - val_loss: 0.1174 - val_accuracy: 0.9453\n",
            "Epoch 19/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9682\n",
            "Epoch 00019: val_loss did not improve from 0.08653\n",
            "169/169 [==============================] - 37s 220ms/step - loss: 0.0873 - accuracy: 0.9682 - val_loss: 0.1824 - val_accuracy: 0.9138\n",
            "Epoch 20/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9801\n",
            "Epoch 00020: val_loss did not improve from 0.08653\n",
            "169/169 [==============================] - 38s 223ms/step - loss: 0.0581 - accuracy: 0.9801 - val_loss: 0.1906 - val_accuracy: 0.9232\n",
            "Epoch 21/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9803\n",
            "Epoch 00021: val_loss did not improve from 0.08653\n",
            "169/169 [==============================] - 38s 224ms/step - loss: 0.0563 - accuracy: 0.9803 - val_loss: 0.1464 - val_accuracy: 0.9527\n",
            "Epoch 22/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9801\n",
            "Epoch 00022: val_loss did not improve from 0.08653\n",
            "169/169 [==============================] - 38s 222ms/step - loss: 0.0603 - accuracy: 0.9801 - val_loss: 0.1559 - val_accuracy: 0.9390\n",
            "Epoch 23/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9720\n",
            "Epoch 00023: val_loss did not improve from 0.08653\n",
            "169/169 [==============================] - 37s 219ms/step - loss: 0.0737 - accuracy: 0.9720 - val_loss: 0.1071 - val_accuracy: 0.9674\n",
            "Epoch 24/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 0.9825\n",
            "Epoch 00024: val_loss improved from 0.08653 to 0.06749, saving model to ./model_weights/finalyearproject_antispoofing_model_24-0.976866.h5\n",
            "169/169 [==============================] - 36s 216ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.0675 - val_accuracy: 0.9769\n",
            "Epoch 25/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9761\n",
            "Epoch 00025: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 218ms/step - loss: 0.0638 - accuracy: 0.9761 - val_loss: 0.1987 - val_accuracy: 0.9138\n",
            "Epoch 26/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9818\n",
            "Epoch 00026: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 214ms/step - loss: 0.0559 - accuracy: 0.9818 - val_loss: 0.2297 - val_accuracy: 0.9201\n",
            "Epoch 27/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9810\n",
            "Epoch 00027: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 216ms/step - loss: 0.0568 - accuracy: 0.9810 - val_loss: 0.1140 - val_accuracy: 0.9516\n",
            "Epoch 28/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9782\n",
            "Epoch 00028: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 217ms/step - loss: 0.0658 - accuracy: 0.9782 - val_loss: 0.1382 - val_accuracy: 0.9527\n",
            "Epoch 29/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9841\n",
            "Epoch 00029: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 217ms/step - loss: 0.0437 - accuracy: 0.9841 - val_loss: 0.1292 - val_accuracy: 0.9432\n",
            "Epoch 30/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9877\n",
            "Epoch 00030: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 217ms/step - loss: 0.0346 - accuracy: 0.9877 - val_loss: 0.1761 - val_accuracy: 0.9453\n",
            "Epoch 31/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9863\n",
            "Epoch 00031: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 216ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0920 - val_accuracy: 0.9695\n",
            "Epoch 32/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9903\n",
            "Epoch 00032: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 214ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.1488 - val_accuracy: 0.9390\n",
            "Epoch 33/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9810\n",
            "Epoch 00033: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 213ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.2811 - val_accuracy: 0.8938\n",
            "Epoch 34/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9848\n",
            "Epoch 00034: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 213ms/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.1629 - val_accuracy: 0.9380\n",
            "Epoch 35/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9825\n",
            "Epoch 00035: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 213ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.1462 - val_accuracy: 0.9411\n",
            "Epoch 36/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9784\n",
            "Epoch 00036: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 213ms/step - loss: 0.0554 - accuracy: 0.9784 - val_loss: 0.1201 - val_accuracy: 0.9516\n",
            "Epoch 37/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9853\n",
            "Epoch 00037: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 214ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 0.0807 - val_accuracy: 0.9716\n",
            "Epoch 38/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9879\n",
            "Epoch 00038: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 214ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.2410 - val_accuracy: 0.9306\n",
            "Epoch 39/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9912\n",
            "Epoch 00039: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 214ms/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.1922 - val_accuracy: 0.9411\n",
            "Epoch 40/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 0.9846\n",
            "Epoch 00040: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.2398 - val_accuracy: 0.9169\n",
            "Epoch 41/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9855\n",
            "Epoch 00041: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0439 - accuracy: 0.9855 - val_loss: 0.1811 - val_accuracy: 0.9464\n",
            "Epoch 42/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9908\n",
            "Epoch 00042: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.2299 - val_accuracy: 0.9348\n",
            "Epoch 43/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9896\n",
            "Epoch 00043: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0262 - accuracy: 0.9896 - val_loss: 0.1563 - val_accuracy: 0.9453\n",
            "Epoch 44/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9834\n",
            "Epoch 00044: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0439 - accuracy: 0.9834 - val_loss: 0.2495 - val_accuracy: 0.9159\n",
            "Epoch 45/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9938\n",
            "Epoch 00045: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.1805 - val_accuracy: 0.9327\n",
            "Epoch 46/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9874\n",
            "Epoch 00046: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 208ms/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 0.1120 - val_accuracy: 0.9632\n",
            "Epoch 47/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9884\n",
            "Epoch 00047: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 210ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.1170 - val_accuracy: 0.9548\n",
            "Epoch 48/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9841\n",
            "Epoch 00048: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 208ms/step - loss: 0.0415 - accuracy: 0.9841 - val_loss: 0.1061 - val_accuracy: 0.9685\n",
            "Epoch 49/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9903\n",
            "Epoch 00049: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.1127 - val_accuracy: 0.9579\n",
            "Epoch 50/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9915\n",
            "Epoch 00050: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 207ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.1788 - val_accuracy: 0.9359\n",
            "Epoch 51/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9882\n",
            "Epoch 00051: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 206ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.1705 - val_accuracy: 0.9253\n",
            "Epoch 52/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9893\n",
            "Epoch 00052: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 207ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.1190 - val_accuracy: 0.9537\n",
            "Epoch 53/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9903\n",
            "Epoch 00053: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 0.1576 - val_accuracy: 0.9548\n",
            "Epoch 54/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9900\n",
            "Epoch 00054: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.2132 - val_accuracy: 0.9295\n",
            "Epoch 55/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9941\n",
            "Epoch 00055: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.1705 - val_accuracy: 0.9401\n",
            "Epoch 56/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9893\n",
            "Epoch 00056: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.0678 - val_accuracy: 0.9748\n",
            "Epoch 57/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9953\n",
            "Epoch 00057: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 206ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.1468 - val_accuracy: 0.9516\n",
            "Epoch 58/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9891\n",
            "Epoch 00058: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 206ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.1563 - val_accuracy: 0.9401\n",
            "Epoch 59/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9853\n",
            "Epoch 00059: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 207ms/step - loss: 0.0372 - accuracy: 0.9853 - val_loss: 0.1040 - val_accuracy: 0.9548\n",
            "Epoch 60/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9905\n",
            "Epoch 00060: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 205ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0996 - val_accuracy: 0.9674\n",
            "Epoch 61/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9962\n",
            "Epoch 00061: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 207ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0903 - val_accuracy: 0.9674\n",
            "Epoch 62/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9903\n",
            "Epoch 00062: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 207ms/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 0.1654 - val_accuracy: 0.9579\n",
            "Epoch 63/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9929\n",
            "Epoch 00063: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.1618 - val_accuracy: 0.9432\n",
            "Epoch 64/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9865\n",
            "Epoch 00064: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 213ms/step - loss: 0.0338 - accuracy: 0.9865 - val_loss: 0.1085 - val_accuracy: 0.9632\n",
            "Epoch 65/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9879\n",
            "Epoch 00065: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 220ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 0.1068 - val_accuracy: 0.9548\n",
            "Epoch 66/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9927\n",
            "Epoch 00066: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 37s 217ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.1149 - val_accuracy: 0.9674\n",
            "Epoch 67/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9922\n",
            "Epoch 00067: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0881 - val_accuracy: 0.9737\n",
            "Epoch 68/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9919\n",
            "Epoch 00068: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.1673 - val_accuracy: 0.9495\n",
            "Epoch 69/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9938\n",
            "Epoch 00069: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 212ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.0748 - val_accuracy: 0.9842\n",
            "Epoch 70/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9934\n",
            "Epoch 00070: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.1276 - val_accuracy: 0.9548\n",
            "Epoch 71/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9915\n",
            "Epoch 00071: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.1185 - val_accuracy: 0.9474\n",
            "Epoch 72/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9955\n",
            "Epoch 00072: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0845 - val_accuracy: 0.9769\n",
            "Epoch 73/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9900\n",
            "Epoch 00073: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.1797 - val_accuracy: 0.9453\n",
            "Epoch 74/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9948\n",
            "Epoch 00074: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.1499 - val_accuracy: 0.9516\n",
            "Epoch 75/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9931\n",
            "Epoch 00075: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.1465 - val_accuracy: 0.9527\n",
            "Epoch 76/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9924\n",
            "Epoch 00076: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.2186 - val_accuracy: 0.9274\n",
            "Epoch 77/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9931\n",
            "Epoch 00077: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.1873 - val_accuracy: 0.9411\n",
            "Epoch 78/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9929\n",
            "Epoch 00078: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0176 - accuracy: 0.9929 - val_loss: 0.2242 - val_accuracy: 0.9548\n",
            "Epoch 79/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9910\n",
            "Epoch 00079: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.2679 - val_accuracy: 0.9274\n",
            "Epoch 80/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9934\n",
            "Epoch 00080: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.2186 - val_accuracy: 0.8970\n",
            "Epoch 81/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9927\n",
            "Epoch 00081: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.1133 - val_accuracy: 0.9569\n",
            "Epoch 82/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9936\n",
            "Epoch 00082: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 215ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0953 - val_accuracy: 0.9600\n",
            "Epoch 83/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9889\n",
            "Epoch 00083: val_loss did not improve from 0.06749\n",
            "169/169 [==============================] - 36s 212ms/step - loss: 0.0329 - accuracy: 0.9889 - val_loss: 0.1154 - val_accuracy: 0.9569\n",
            "Epoch 84/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9936\n",
            "Epoch 00084: val_loss improved from 0.06749 to 0.06345, saving model to ./model_weights/finalyearproject_antispoofing_model_84-0.975815.h5\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0634 - val_accuracy: 0.9758\n",
            "Epoch 85/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9938\n",
            "Epoch 00085: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.1141 - val_accuracy: 0.9537\n",
            "Epoch 86/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9889\n",
            "Epoch 00086: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0300 - accuracy: 0.9889 - val_loss: 0.0685 - val_accuracy: 0.9695\n",
            "Epoch 87/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9945\n",
            "Epoch 00087: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 215ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.3036 - val_accuracy: 0.8822\n",
            "Epoch 88/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9917\n",
            "Epoch 00088: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 214ms/step - loss: 0.0200 - accuracy: 0.9917 - val_loss: 0.2059 - val_accuracy: 0.9338\n",
            "Epoch 89/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
            "Epoch 00089: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 212ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.1681 - val_accuracy: 0.9432\n",
            "Epoch 90/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9943\n",
            "Epoch 00090: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 213ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.1651 - val_accuracy: 0.9474\n",
            "Epoch 91/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9915\n",
            "Epoch 00091: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.2181 - val_accuracy: 0.8854\n",
            "Epoch 92/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9934\n",
            "Epoch 00092: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.3411 - val_accuracy: 0.9075\n",
            "Epoch 93/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9950\n",
            "Epoch 00093: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 35s 209ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.1428 - val_accuracy: 0.9537\n",
            "Epoch 94/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9922\n",
            "Epoch 00094: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 35s 210ms/step - loss: 0.0293 - accuracy: 0.9922 - val_loss: 0.1045 - val_accuracy: 0.9706\n",
            "Epoch 95/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9931\n",
            "Epoch 00095: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.1639 - val_accuracy: 0.9558\n",
            "Epoch 96/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9938\n",
            "Epoch 00096: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 211ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.1948 - val_accuracy: 0.9569\n",
            "Epoch 97/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9941\n",
            "Epoch 00097: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 210ms/step - loss: 0.0150 - accuracy: 0.9941 - val_loss: 0.3063 - val_accuracy: 0.9369\n",
            "Epoch 98/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9929\n",
            "Epoch 00098: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 212ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.4265 - val_accuracy: 0.9117\n",
            "Epoch 99/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9941\n",
            "Epoch 00099: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 212ms/step - loss: 0.0162 - accuracy: 0.9941 - val_loss: 0.1327 - val_accuracy: 0.9495\n",
            "Epoch 100/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9964\n",
            "Epoch 00100: val_loss did not improve from 0.06345\n",
            "169/169 [==============================] - 36s 212ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.1051 - val_accuracy: 0.9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#serialize model to json\n",
        "model_json = cnn.to_json()\n",
        "with open('finalyearproject_antispoofing_cnn_model.json','w') as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "metadata": {
        "id": "_jMTzYa8YttB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "def check_fakes(path,category_type):\n",
        "  predictor = {}\n",
        "  path = os.path.join(path,category_type)\n",
        "  for img in os.listdir(path):\n",
        "    try:\n",
        "      img = image.load_img(os.path.join(path,img),target_size=(160,160))\n",
        "      img = image.img_to_array(img)\n",
        "      img = np.expand_dims(img,axis=0)\n",
        "      img = img/255.0\n",
        "      prediction = cnn.predict(img)\n",
        "      if prediction > 0.5:\n",
        "        prediction_class = 1\n",
        "      else:\n",
        "        prediction_class = 0\n",
        "      result = categories[prediction_class]\n",
        "      if result not in predictor:\n",
        "        predictor[result] = 1\n",
        "      else:\n",
        "        predictor[result] += 1\n",
        "    except Exception as e:\n",
        "      pass\n",
        "  return predictor\n",
        "      "
      ],
      "metadata": {
        "id": "CHQW3CslBuHL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_fakes(test_dir,categories[1]) # testing for spoof images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDuCALmWBt8C",
        "outputId": "ac908b6f-4686-43b4-ebd3-b64096e38d91"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'real': 7, 'spoof': 467}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_fakes(test_dir,categories[0]) # testing for real images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5kh0yAMFR-L",
        "outputId": "7c09b362-f91a-4530-9334-d69ac01000f6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'real': 452, 'spoof': 25}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}